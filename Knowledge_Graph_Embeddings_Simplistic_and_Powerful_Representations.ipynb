{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Knowledge Graph Embeddings: Simplistic and Powerful Representations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DougBR/KGs/blob/main/Knowledge_Graph_Embeddings_Simplistic_and_Powerful_Representations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CS224W Final Project - Knowledge Graph Embeddings**\n",
        "\n",
        "*written by Mark Endo*"
      ],
      "metadata": {
        "id": "0hRfGiXNyp3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this Colab, we will write a pipeline to learn knowledge graph (KG) embeddings for the task of predicting missing triples. Knowledge graphs are an example of heterogenous graphs that capture entities, types, and relationships. We will be working with the [Freebase](https://paperswithcode.com/dataset/fb15k) dataset (FB15k-237) and implementing [TransE](https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf) in order to embed the graph.\n",
        "\n",
        "In this notebook, we first learn how to process the FB15k-237 dataset using PyTorch Geometric, and we analyze the graph using NetworkX and an external tool called [Gephi](https://gephi.org/). Then, we dive into building the TransE architecture with PyTorch. Lastly, we train and evaluate our model for the task of predicting missing tails. We measure our method's performance using the Hits @ 10, Mean Rank, and MRR (mean reciprocal rank) metrics."
      ],
      "metadata": {
        "id": "a6pVeJTUy3Ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Device\n",
        "\n",
        "To achieve optimal results in a short period of time, it is recommended to run this Colab on a GPU. If you are using a GPU to run this Colab, make sure to set the variable  `use_gpu` to `True`\n",
        "(In order for this Colab to run in a short amount of time without a GPU, we train for less epochs and evaluate less often)"
      ],
      "metadata": {
        "id": "riJDKT3r6kbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# whether you are using a GPU to run this Colab\n",
        "use_gpu = False\n",
        "# whether you are using a custom GCE env to run the Colab (uses different CUDA)\n",
        "custom_GCE_env = False"
      ],
      "metadata": {
        "id": "EggJqoBI6c4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "sEul6gpL7iUi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2YzFIEVyNts",
        "outputId": "c594538e-5e12-4780-db76-7f2e4dcb5877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "if custom_GCE_env:\n",
        "  !pip install torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu102.html\n",
        "  !pip install torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cu102.html\n",
        "else:\n",
        "  !pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "  !pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "import math\n",
        "torch_geometric.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ENdUD9p2D-9o",
        "outputId": "ecf368c4-28ea-444a-97d6-c734a44bbf2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.2'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing FB15k-237 Dataset\n",
        "\n",
        "FB15k-237 captures entities, types, and relations from the Freebase dataset. There are a total of 310,116 triplets, with 14,541 entities and 237 relations. Each triplet is represented as $(h, l, t)$, where $h$ is the head entity, $t$ represents the tail entity, and $l$ represents the relation type. We will be storing this dataset a PyTorch Geometric `InMemoryDataset`. The advantage of using this class is that we can load the data all at once and easily access it later. In order to define the `FB15Dataset` class as inheriting from the `InMemoryDataset`, we have to implement the following methods: `raw_file_names()`, `processed_file_names`, `download()`, and `process()`. More information about these methods can be found [here](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_dataset.html).\n",
        "\n",
        "Importantly, in the `process()` method we will load the dataset into train, valid, and test splits, where each has a Tensor representing its `edge_index` and `edge_type`. Later on, we can access the head entities with `edge_index[0,:]` and the tail entities with `edge_index[1,:]`. \n"
      ],
      "metadata": {
        "id": "fexUN8enEB_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FB15kDataset(torch_geometric.data.InMemoryDataset):\n",
        "  r\"\"\"FB15-237 dataset from Freebase.\n",
        "  Follows similar structure to torch_geometric.datasets.rel_link_pred_dataset\n",
        "  \n",
        "  Args: \n",
        "    root (string): Root directory where the dataset should be saved.\n",
        "    transform (callable, optional): A function/transform that takes in an\n",
        "        :obj:`torch_geometric.data.Data` object and returns a transformed\n",
        "        version. The data object will be transformed before every access.\n",
        "        (default: :obj:`None`)\n",
        "    pre_transform (callable, optional): A function/transform that takes in\n",
        "        an :obj:`torch_geometric.data.Data` object and returns a\n",
        "        transformed version. The data object will be transformed before\n",
        "        being saved to disk. (default: :obj:`None`)\n",
        "  \"\"\"\n",
        "  data_path = 'https://raw.githubusercontent.com/DeepGraphLearning/' \\\n",
        "              'KnowledgeGraphEmbedding/master/data/FB15k-237'\n",
        "  def __init__(self, root, transform=None, pre_transform=None):\n",
        "    super().__init__(root, transform, pre_transform)\n",
        "    self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return ['train.txt', 'valid.txt', 'test.txt', \n",
        "            'entities.dict', 'relations.dict']\n",
        "  \n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return ['data.pt']\n",
        "\n",
        "  @property\n",
        "  def raw_dir(self):\n",
        "    return os.path.join(self.root, 'raw')\n",
        "  \n",
        "  def download(self):\n",
        "      for file_name in self.raw_file_names:\n",
        "        torch_geometric.data.download_url(f'{self.data_path}/{file_name}',\n",
        "                                          self.raw_dir)\n",
        "\n",
        "  def process(self):\n",
        "    with open(os.path.join(self.raw_dir, 'entities.dict'), 'r') as f:\n",
        "      lines = [row.split('\\t') for row in f.read().split('\\n')[:-1]]\n",
        "      entities_dict = {key: int(value) for value, key in lines}\n",
        "\n",
        "    with open(os.path.join(self.raw_dir, 'relations.dict'), 'r') as f:\n",
        "      lines = [row.split('\\t') for row in f.read().split('\\n')[:-1]]\n",
        "      relations_dict = {key: int(value) for value, key in lines}\n",
        "\n",
        "    kwargs = {}\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "      with open(os.path.join(self.raw_dir, f'{split}.txt'), 'r') as f:\n",
        "        lines = [row.split('\\t') for row in f.read().split('\\n')[:-1]]\n",
        "        heads = [entities_dict[row[0]] for row in lines]\n",
        "        relations = [relations_dict[row[1]] for row in lines]\n",
        "        tails = [entities_dict[row[2]] for row in lines]\n",
        "        kwargs[f'{split}_edge_index'] = torch.tensor([heads, tails])\n",
        "        kwargs[f'{split}_edge_type'] = torch.tensor(relations)\n",
        "\n",
        "    _data = torch_geometric.data.Data(num_entities=len(entities_dict), \n",
        "                                      num_relations=len(relations_dict),\n",
        "                                      **kwargs)\n",
        "    \n",
        "    if self.pre_transform is not None:\n",
        "      _data = self.pre_transform(_data)\n",
        "\n",
        "    data, slices = self.collate([_data])\n",
        "\n",
        "    torch.save((data, slices), self.processed_paths[0])\n",
        "\n",
        "FB15k_dset = FB15kDataset(root='FB15k')\n",
        "data = FB15k_dset[0]"
      ],
      "metadata": {
        "id": "QhLMk6zrEAeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Our Data\n",
        "\n",
        "Now that we have easy access to our data, we will analyze it and export it into a format that can be visualized using tools such as [Gephi](https://gephi.org/). First, lets take a look at the size of our graph and it's different splits."
      ],
      "metadata": {
        "id": "O16ot_1QOWYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The graph has a total of {data.num_entities} entities and {data.num_relations} relations.')\n",
        "print(f'The train split has {data.train_edge_type.size()[0]} relation triples.')\n",
        "print(f'The valid split has {data.valid_edge_type.size()[0]} relation triples.')\n",
        "print(f'The test split has {data.test_edge_type.size()[0]} relation triples.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9so6qh8Mc86",
        "outputId": "86d61476-2ad5-4c57-b1f5-73a38722fc8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The graph has a total of 14541 entities and 237 relations.\n",
            "The train split has 272115 relation triples.\n",
            "The valid split has 17535 relation triples.\n",
            "The test split has 20466 relation triples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how this dataset has a very large number of entities and relation triples. This means that the graph will be very hard to visualize using standard tools like NetworkX and matplotlib. So, we will export the data so it can be visualized using tools made for large graphs. Even with these tools, the graph can still be quite difficult to manage, so we will sample the graph before exporting it."
      ],
      "metadata": {
        "id": "cTFAJPzRQAn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import networkx as nx\n",
        "\n",
        "def visualize_graph(data, out_path, reduction=200):\n",
        "  nodes = range(data.num_entities)\n",
        "  edges = []\n",
        "  edge_relations = []\n",
        "\n",
        "  num_edges = 0\n",
        "  for i in range(data.train_edge_type.size()[0]):\n",
        "    if random.randint(1, reduction) == 1: # only take random subset of edges\n",
        "      edges.append((int(data.train_edge_index[0,i]),\n",
        "                    int(data.train_edge_index[1,i])))\n",
        "      edge_relations.append(int(data.train_edge_type[i]))\n",
        "      num_edges += 1\n",
        "  \n",
        "  G = nx.DiGraph()\n",
        "  G.add_edges_from(edges)\n",
        "  for i, (head, tail) in enumerate(edges):\n",
        "    G[head][tail][\"relation\"] = edge_relations[i]\n",
        "  nx.write_gexf(G, path=out_path)\n",
        "\n",
        "visualize_graph(data, 'FB15k_sampled_dset.gexf')"
      ],
      "metadata": {
        "id": "pL3VqKgyMtOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what our resulting graph looks like in Gephi. The most common relationship types are at the top left.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=12h5fuXznj0llqSDPbvA4jmaRVDO7p5dr) "
      ],
      "metadata": {
        "id": "2RFR3uj9nWJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TransE Implementation\n",
        "\n",
        "Now, we will lay out the architecture for TransE. As stated earlier, the edges in KGs are represented as triples $(h, r, t)$. In TransE, we model both the entities and the relations in an embedding space and try to adjust the embeddings such at $\\textbf h + \\textbf l \\approx \\textbf t$ (where bold letters are embeddings). Formally, the loss is:\n",
        "\n",
        "$\\sum_{((h, l, t), (h', l, t')) \\in T_{batch}} [\\gamma + d(\\textbf{h} + \\textbf{l}, \\textbf t) - d(\\textbf{h'} + \\textbf l, \\textbf{t'})]$\n",
        "\n",
        "where $(h', l, t')$ represents a corrupted triple by either replacing the head or tail with a random entity.\n",
        "\n",
        "In total, the TransE algorithm is as follows\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=18XD6duW40-jddEXgZzGHzyvjAstGv34P) \n",
        "\n",
        "In terms of model implementation, we will initialize $\\textbf l$ and $\\textbf e$ according to the pseudocode above. To calculate $d(\\textbf{h} + \\textbf{l}, \\textbf t)$, we take the L2 norm of $\\textbf h + \\textbf l - \\textbf t$.\n",
        "\n",
        "*Note: we normalize $\\textbf e$ every epoch instead of every minibatch because it led to improved performance, so it does not appear in our model code.*"
      ],
      "metadata": {
        "id": "IToxzuzDpNHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransE(torch.nn.Module):\n",
        "  def __init__(self, num_entities, num_relations, device, embedding_dim=50, \n",
        "               margin=1.0, visualize=False):\n",
        "    super(TransE, self).__init__()\n",
        "    self.device = device\n",
        "    self.num_entities = num_entities\n",
        "    self.num_relations = num_relations\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.entities_emb = self.init_emb(num_entities, embedding_dim, emb_type='entity')\n",
        "    self.relations_emb = self.init_emb(num_relations, embedding_dim, emb_type='relation')\n",
        "\n",
        "    self.criterion = torch.nn.MarginRankingLoss(margin=margin, reduction='none')\n",
        "\n",
        "    self.visualize = visualize\n",
        "    # used for visualization\n",
        "    if visualize:\n",
        "      self.pca = PCA(n_components=2)\n",
        "\n",
        "\n",
        "  def init_emb(self, size, dim, emb_type='relation'):\n",
        "    emb = torch.nn.Embedding(num_embeddings=size, \n",
        "                             embedding_dim=dim)\n",
        "    uniform_max = 6 / np.sqrt(dim) # 6 / sqrt(k)\n",
        "    emb.weight.data.uniform_(-uniform_max, uniform_max)\n",
        "    if emb_type == 'relation':\n",
        "      emb_norm = torch.norm(emb.weight.data, dim=1, keepdim=True)\n",
        "      emb.weight.data = emb.weight.data / emb_norm # l = l / ||l||\n",
        "    return emb\n",
        "\n",
        "  def forward(self, edge_index, negative_edge_index, edge_type):\n",
        "    positive_distance = self.distance(edge_index, edge_type)\n",
        "    negative_distance = self.distance(negative_edge_index, edge_type)\n",
        "    return self.loss(positive_distance, negative_distance)\n",
        "  \n",
        "  def predict(self, edge_index, edge_type):\n",
        "    return self.distance(edge_index, edge_type)\n",
        "\n",
        "  def distance(self, edge_index, edge_type):\n",
        "    heads = edge_index[0,:]\n",
        "    tails = edge_index[1,:]\n",
        "    return (self.entities_emb(heads) + self.relations_emb(edge_type) - \\\n",
        "            self.entities_emb(tails)).norm(p=2., dim=1, keepdim=True) # l2 norm of h + l - t\n",
        "  \n",
        "  def loss(self, positive_distance, negative_distance):\n",
        "    y = torch.tensor([-1], dtype=torch.long, device=self.device)\n",
        "    return self.criterion(positive_distance, negative_distance, y).sum()"
      ],
      "metadata": {
        "id": "r8JL6AAopfwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing\n",
        "\n",
        "Now that we have implemented data processing and the model, it is time to train and test on the task of predicting missing tails."
      ],
      "metadata": {
        "id": "pHO2ZXA24f-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One key aspect of training our model is creating corrupted triples by either replacing the head or tail with a random entity. We will do this once for every epoch, randomly replacing heads and tails"
      ],
      "metadata": {
        "id": "p2vBRhdW5GOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_corrupted_edge_index(edge_index, edge_type, num_entities):\n",
        "  corrupt_head_or_tail = torch.randint(high=2, size=edge_type.size(),\n",
        "                                       device=device)\n",
        "  random_entities = torch.randint(high=num_entities, \n",
        "                                  size=edge_type.size(), device=device)\n",
        "  # corrupt when 1, otherwise regular head\n",
        "  heads = torch.where(corrupt_head_or_tail == 1, random_entities, \n",
        "                      edge_index[0,:])\n",
        "  # corrupt when 0, otherwise regular tail\n",
        "  tails = torch.where(corrupt_head_or_tail == 0, random_entities, \n",
        "                      edge_index[1,:])\n",
        "  return torch.stack([heads, tails], dim=0)"
      ],
      "metadata": {
        "id": "NEpCiWxW4e6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other than corrupting samples, the training process is pretty standard. One thing to keep in mind is training samples are shuffled between epochs."
      ],
      "metadata": {
        "id": "yy8QmpfKchNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, optimizer, device, epochs=50, batch_size=128,\n",
        "          eval_batch_size=256, valid_freq=5):\n",
        "  train_edge_index = data.train_edge_index.to(device)\n",
        "  train_edge_type = data.train_edge_type.to(device)\n",
        "\n",
        "  best_valid_score = 0\n",
        "  valid_scores = None\n",
        "  test_scores = None\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    # e = e / ||e||\n",
        "    entities_norm = torch.norm(model.entities_emb.weight.data, dim=1, keepdim=True)\n",
        "    model.entities_emb.weight.data = model.entities_emb.weight.data / entities_norm\n",
        "\n",
        "    # shuffle train set each batch\n",
        "    num_triples = data.train_edge_type.size()[0]\n",
        "    shuffled_triples_order = np.arange(num_triples)\n",
        "    np.random.shuffle(shuffled_triples_order)\n",
        "    shuffled_edge_index = train_edge_index[:, shuffled_triples_order]\n",
        "    shuffled_edge_type = train_edge_type[shuffled_triples_order]\n",
        "\n",
        "    negative_edge_index = create_corrupted_edge_index(shuffled_edge_index,\n",
        "                                                      shuffled_edge_type,\n",
        "                                                      data.num_entities)\n",
        "    \n",
        "    total_loss = 0\n",
        "    total_size = 0\n",
        "    for batch_idx in range(math.ceil(num_triples / batch_size)):\n",
        "      batch_start = batch_idx * batch_size\n",
        "      batch_end = (batch_idx + 1) * batch_size\n",
        "      batch_edge_index = shuffled_edge_index[:,batch_start:batch_end]\n",
        "      batch_negative_edge_index = negative_edge_index[:,batch_start:batch_end]\n",
        "      batch_edge_type = shuffled_edge_type[batch_start:batch_end]\n",
        "      loss = model(batch_edge_index, batch_negative_edge_index, batch_edge_type)\n",
        "      total_loss += loss.item()\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_size += batch_edge_type.size()[0]\n",
        "      if model.visualize  and epoch == 0 \\\n",
        "      and batch_idx % 100 == 0:\n",
        "        visualize_emb(model, batch_idx)\n",
        "    print(f'Epoch {epoch}, train loss equals {total_loss / total_size}')\n",
        "    if (epoch + 1) % valid_freq == 0:\n",
        "      mrr_score, mr_score, hits_at_10 = eval(model, data.valid_edge_index.to(device),\n",
        "                                             data.valid_edge_type.to(device),\n",
        "                                             data.num_entities, device)\n",
        "      print(f'Validation score equals {mrr_score}, {mr_score}, {hits_at_10}')\n",
        "      if mrr_score > best_valid_score:\n",
        "        valid_scores = (mrr_score, mr_score, hits_at_10)\n",
        "        test_mmr_score, test_mr_score, test_hits_at_10 = \\\n",
        "                                        eval(model, data.valid_edge_index.to(device),\n",
        "                                             data.valid_edge_type.to(device),\n",
        "                                             data.num_entities, device)\n",
        "        test_scores = (test_mmr_score, test_mr_score, test_hits_at_10)\n",
        "    # break\n",
        "  print(f'Test scores from best model (mmr, mr, h@10): {test_scores}')\n"
      ],
      "metadata": {
        "id": "75dAeMi9H44Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For metrics, we measure Hits @ 10, Mean Rank, and MRR (mean reciprocal rank).\n",
        "\n",
        "First, Hits @ 10 = $\\frac{|\\{r \\in P | r \\leq 10\\}|}{|P|}$, where $|P|$ is the number of rank scores and $r$ is rank.\n",
        "\n",
        "Second, Mean Rank = $\\frac{1}{|P|}\\sum_{r \\in P}r$\n",
        "\n",
        "Third, MMR = $\\frac{1}{|P|}\\sum_{r \\in P}\\frac{1}{r}$\n",
        "\n",
        "MRR is the most trusted out of the three metrics. Hits @ 10 suffers from the fact that any rank above 10 is not differentiated, and Mean Rank suffers from the number of entities highly affecting the overall score. There is more information about the metrics [here](https://arxiv.org/pdf/2002.06914.pdf).\n",
        "\n",
        "For our implementations, we divide by $|P|$ after adding up all the scores in the minibatches."
      ],
      "metadata": {
        "id": "Oc-lJydiDKBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mrr(predictions, gt):\n",
        "  \"\"\"MRR score adopted from \n",
        "  https://github.com/mklimasz/TransE-PyTorch/blob/master/metric.py\n",
        "  \"\"\"\n",
        "  indices = predictions.argsort()\n",
        "  return (1.0 / (indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
        "\n",
        "def mr(predictions, gt):\n",
        "  indices = predictions.argsort()\n",
        "  return ((indices == gt).nonzero()[:, 1].float().add(1.0)).sum().item()\n",
        "\n",
        "def hit_at_k(predictions, gt, device, k=10):\n",
        "  \"\"\"Hit @ k score adopted from \n",
        "  https://github.com/mklimasz/TransE-PyTorch/blob/master/metric.py\n",
        "  \"\"\"\n",
        "  zero_tensor = torch.tensor([0], device=device)\n",
        "  one_tensor = torch.tensor([1], device=device)\n",
        "  _, indices = predictions.topk(k=k, largest=False)\n",
        "  return torch.where(indices == gt, one_tensor, zero_tensor).sum().item()"
      ],
      "metadata": {
        "id": "Zj3qZ4G98qo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For testing, we remove each tail and replace it with every entity in the graph. We then calculate the distances between $\\textbf h + \\textbf l$ and every entity, and the entities are sorted in ascending order. "
      ],
      "metadata": {
        "id": "W1LpbUGg8_Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, edge_index, edge_type, num_entities, device, eval_batch_size=64):\n",
        "  model.eval()\n",
        "  num_triples = edge_type.size()[0]\n",
        "  mrr_score = 0\n",
        "  mr_score = 0\n",
        "  hits_at_10 = 0\n",
        "  num_predictions = 0\n",
        "\n",
        "  for batch_idx in range(math.ceil(num_triples / eval_batch_size)):\n",
        "    batch_start = batch_idx * eval_batch_size\n",
        "    batch_end = (batch_idx + 1) * eval_batch_size\n",
        "    batch_edge_index = edge_index[:,batch_start:batch_end]\n",
        "    batch_edge_type = edge_type[batch_start:batch_end]\n",
        "    batch_size = batch_edge_type.size()[0] # can be different on last batch\n",
        "\n",
        "    all_entities = torch.arange(end=num_entities, \n",
        "                                device=device).unsqueeze(0).repeat(batch_size, 1)\n",
        "    head_repeated = batch_edge_index[0,:].reshape(-1, 1).repeat(1, num_entities)\n",
        "    relation_repeated = batch_edge_type.reshape(-1, 1).repeat(1, num_entities)\n",
        "\n",
        "    head_squeezed = head_repeated.reshape(-1)\n",
        "    relation_squeezed = relation_repeated.reshape(-1)\n",
        "    all_entities_squeezed = all_entities.reshape(-1)\n",
        "\n",
        "    entity_index_replaced_tail = torch.stack((head_squeezed,all_entities_squeezed))\n",
        "    predictions = model.predict(entity_index_replaced_tail, relation_squeezed)\n",
        "    predictions = predictions.reshape(batch_size, -1)\n",
        "    gt = batch_edge_index[1,:].reshape(-1, 1)\n",
        "\n",
        "    mrr_score += mrr(predictions, gt)\n",
        "    mr_score += mr(predictions, gt)\n",
        "    hits_at_10 += hit_at_k(predictions, gt, device=device, k=10)\n",
        "    num_predictions += predictions.size()[0]\n",
        "\n",
        "  mrr_score = mrr_score / num_predictions\n",
        "  mr_score = mr_score / num_predictions\n",
        "  hits_at_10 = hits_at_10 / num_predictions\n",
        "  return mrr_score, mr_score, hits_at_10"
      ],
      "metadata": {
        "id": "TRZHI1Ur_etu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize embeddings\n",
        "\n",
        "Since we are using shallow embeddings to represent entities and relations, it is straightforward to visualize the embeddings during training. Here, we use PCA to transform the 50 dimensional vectors to 2d."
      ],
      "metadata": {
        "id": "sCYEjjKDMjWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "def visualize_emb(model, idx):\n",
        "  if idx == 0:\n",
        "    out = model.pca.fit_transform(model.relations_emb.weight.data)\n",
        "  else:\n",
        "    out = model.pca.transform(model.relations_emb.weight.data)\n",
        "  cmap = cm.get_cmap('tab20')\n",
        "  fig, ax = plt.subplots(figsize=(8,8))\n",
        "  for entity_id in range(np.shape(out)[0]):\n",
        "    ax.scatter(out[entity_id,0], out[entity_id,1], color=cmap(entity_id % 20))\n",
        "  plt.savefig('visualize_relations_emb_' + str(idx) + '.png')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FbMz29l-MqWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Training!\n",
        "\n",
        "Now that we have everything set, we can start training.\n",
        "\n",
        "*Note: evaluation will take quite a while without a GPU (~ 5 minutes)*"
      ],
      "metadata": {
        "id": "Iw8E64HHdOnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "if use_gpu:\n",
        "  epochs = 50\n",
        "  valid_freq = 5\n",
        "else:\n",
        "  epochs = 10\n",
        "  valid_freq = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = TransE(data.num_entities, data.num_relations, device, visualize=False).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "train(model, data, optimizer, device, epochs=epochs, valid_freq=valid_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5RtEbV2HpHr",
        "outputId": "a9700cb1-0bc1-4e48-ac37-9e9ead01383d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, train loss equals 0.8450540051001942\n",
            "Epoch 1, train loss equals 0.7025755662292331\n",
            "Epoch 2, train loss equals 0.607560314087836\n",
            "Epoch 3, train loss equals 0.5218951126641717\n",
            "Epoch 4, train loss equals 0.44190907410429464\n",
            "Epoch 5, train loss equals 0.37600184632441114\n",
            "Epoch 6, train loss equals 0.32341098243928285\n",
            "Epoch 7, train loss equals 0.2838035914757863\n",
            "Epoch 8, train loss equals 0.2542663452536475\n",
            "Epoch 9, train loss equals 0.2328555125673947\n",
            "Validation score equals 0.2427326449037176, 607.9158254918734, 0.3835186769318506\n",
            "Test scores from best model (mmr, mr, h@10): (0.2427326449037176, 607.9158254918734, 0.3835186769318506)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a GPU, the test MMR should be around .25, and the Hits @ k should be around .40. Without a GPU, the test MMR should be around .24 and the Hits @ k should be around .38"
      ],
      "metadata": {
        "id": "r8J7iKTqhtk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Weaknesses of TransE for FB15k-237\n",
        "\n",
        "Although TransE is a powerful method for representing knowledge graph embeddings, one relation type that it cannot model is symmetric relations. In this last section, we look at the FB15k-237 dataset and approximate the frequency of symmetric relations.\n",
        "\n",
        "*Note: this cell takes about 2 minutes to complete*"
      ],
      "metadata": {
        "id": "pmgmX5QxmcE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def find_symmetric_relations(edge_index, edge_type, sample=50):\n",
        "  # (h, l, t) ⇒ (t, l, h)\n",
        "  num_triplets = edge_type.size()[0]\n",
        "  shuffled_triplets_order = np.arange(num_triplets)\n",
        "  np.random.shuffle(shuffled_triplets_order)\n",
        "  shuffled_triplets_order = shuffled_triplets_order[:sample]\n",
        "\n",
        "  num_symmetric_relations = 0\n",
        "  # total_relations = 0\n",
        "  for i in list(shuffled_triplets_order):\n",
        "    head = edge_index[0, i]\n",
        "    tail = edge_index[1, i]\n",
        "    relation = edge_type[i]\n",
        "    for j in range(num_triplets):\n",
        "      if i == j:\n",
        "        continue\n",
        "      _head = edge_index[0, j]\n",
        "      _tail = edge_index[1, j]\n",
        "      _relation = edge_type[j]\n",
        "      if (head == _tail and tail == _head and relation == _relation):\n",
        "        num_symmetric_relations += 1\n",
        "  print(f'When sampling {sample} triplets, found {num_symmetric_relations} '\\\n",
        "           'symmetric relations present in the graph.')\n",
        "\n",
        "find_symmetric_relations(data.train_edge_index, data.train_edge_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VjJDqQolF82",
        "outputId": "1db88a2d-0947-432b-bebb-3dae55a17e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When sampling 50 triplets, found 6 symmetric relations present in the graph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BF9VJGxfoGCk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}